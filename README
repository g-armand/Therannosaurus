[README]

Pensez à bien respecter ces étapes pour que le thesaurus soit bien configuré :

Téléchargez main.py, evaluation_list.txt dans un même dossier "therannosaurus".
Créez un dossier "corpus" dans ce dossier principal (il contiendra les corpus pour construire le thésaurus).

Téléchargement des corpus à partir de l'invite de commande :
	Placez vous dans le répertoire "therannosaurus" :
   		cd C:\...\therannosaurus\corpus)

	Téléchargez les corpus :
		curl.exe --output corpusA.tgz --url http://www.linguist.univ-paris-diderot.fr/~mcandito/estrepublicain.a.outmalt.tgz
		curl.exe --output corpusB.tgz --url http://www.linguist.univ-paris-diderot.fr/~mcandito/estrepublicain.b.outmalt.tgz
		curl.exe --output corpusC.tgz --url http://www.linguist.univ-paris-diderot.fr/~mcandito/estrepublicain.c.outmalt.tgz
	
	Décompressez les fichiers :
		tar -xvzf corpusA.tgz
		tar -xvzf corpusB.tgz
		tar -xvzf corpusC.tgz
	
	Supprimez les fichiers compressés :
		delete corpusA.tgz
		delete corpusB.tgz
		delete corpusC.tgz

Téléchargement des librairies nécessaires au bon fonctionnement du thesaurus :
	Placez vous dans votre répertoire de travail.
	Lancez les commandes suivantes depuis l'invite de commande :
		python -m pip install sklearn
		python -m pip install scipy
		python -m pip install numpy


Vous pouvez à présent lancer main.py !



Le thésaurus se manipule de manière interactive ; depuis l'invite de commande, on peut choisir de :
	- lancer un test qui compare les résultats obtenus par le thésaurus à ceux donnés par des humains (run et stop immédiatement après) ;
	- ou alors, proposer un mot et extraire les 10 mots les plus similaires depuis le corpus (run une fois et possibilité de chercher des mots indéfinniement).

Ces deux solutions sont celles dont les paramètres sont proposés par défaut sur les performances les plus optimales.

Si vous souhaitez regénérer la matrice avec vos propres paramètres, il suffit de rentrer un des deux bloc suivants:
(Veillez à ne pas changer les valeurs de "testing" et "sparse_cosine_matrix".)
(Veillez à ne pas mettre la valeur de count_documents au delà de 78(le nombre de documents dans le corpus).)


#Tester les performances :
matrix = load_data_and_compute_matrix(testing=True, only_nouns=False, consider_index=False, count_documents=1, sparse_cosine_matrix=False)
test(matrix)

#Tester un mot :
matrix = load_data_and_compute_matrix(testing=False, only_nouns=False, consider_index=False, count_documents=1, sparse_cosine_matrix=True)
find_most_similar(matrix, "VOTRE MOT ICI")
find_most_similar(matrix, "VOTRE MOT2 ICI")
find_most_similar(matrix, "VOTRE MOT3 ICI")
...

